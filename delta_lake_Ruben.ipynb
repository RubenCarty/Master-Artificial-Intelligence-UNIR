{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubenCarty/Master-Artificial-Intelligence-UNIR/blob/main/delta_lake_Ruben.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "-FKQALDBqJVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark\n",
        "\n",
        "!pip install -q delta-spark"
      ],
      "metadata": {
        "id": "XuqTb4meRVVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_delta_spark():\n",
        "  from pyspark.sql import SparkSession\n",
        "  from delta import configure_spark_with_delta_pip\n",
        "  builder = SparkSession.builder.appName(\"KeyFeaturesDeltaLake\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
        "    .config(\"spark.jars.packages\",\"io.delta:delta-core_2.12:2.0.0\")\n",
        "  return configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "spark = _create_delta_spark()"
      ],
      "metadata": {
        "id": "sbQa4btjTrmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "auew7HNtTsel",
        "outputId": "4f86cb04-a9aa-4a7d-fb27-53c8533ecdf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a801ddd00d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://546a3b6f078f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>KeyFeaturesDeltaLake</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Delta Table"
      ],
      "metadata": {
        "id": "zfG_XPCiqLtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.createDataFrame(\n",
        "        data=[(1, \"A\"), (2, \"B\"), (3, \"C\")],\n",
        "        schema=[\"col1\", \"col2\"]\n",
        "    )\n",
        "\n",
        "df1.write \\\n",
        "  .format(\"delta\") \\\n",
        "  .saveAsTable(\"my_delta_table\")\n",
        "\n",
        "query = \"SELECT * FROM my_delta_table ORDER BY col1\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-cB8I3gPqF0",
        "outputId": "d6bb166c-926a-4874-8214-e825317cc7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+\n",
            "|col1|col2|\n",
            "+----+----+\n",
            "|   1|   A|\n",
            "|   2|   B|\n",
            "|   3|   C|\n",
            "+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Features"
      ],
      "metadata": {
        "id": "YHY45irS7jny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Schema Evolution / Enforcement\n",
        "\n",
        "Automatically handles schema variations to prevent insertion of bad records during ingestion"
      ],
      "metadata": {
        "id": "iVceu1MUqRum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New DataFrame with a different schema\n",
        "df2 = spark.createDataFrame(\n",
        "        data=[(4, \"D\", \"X\"), (5, \"E\", \"Y\")],\n",
        "        schema=[\"col1\", \"col2\", \"col3\"]\n",
        "    )\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq-haW7G5CMA",
        "outputId": "7add664d-0769-479e-cff6-8a6d56b3613f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   4|   D|   X|\n",
            "|   5|   E|   Y|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Schema mismatch error\n",
        "try:\n",
        "    df2.write \\\n",
        "      .format(\"delta\") \\\n",
        "      .mode(\"append\") \\\n",
        "      .saveAsTable(\"my_delta_table\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbyXxmEbUev4",
        "outputId": "179557b0-dd51-42bc-8e81-5075a9a1b576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[_LEGACY_ERROR_TEMP_DELTA_0007] A schema mismatch detected when writing to the Delta table (Table ID: 1c322c97-480f-463d-a40b-ae680d16d421).\n",
            "To enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n",
            "'.option(\"mergeSchema\", \"true\")'.\n",
            "For other operations, set the session configuration\n",
            "spark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\n",
            "specific to the operation for details.\n",
            "\n",
            "Table schema:\n",
            "root\n",
            "-- col1: long (nullable = true)\n",
            "-- col2: string (nullable = true)\n",
            "\n",
            "\n",
            "Data schema:\n",
            "root\n",
            "-- col1: long (nullable = true)\n",
            "-- col2: string (nullable = true)\n",
            "-- col3: string (nullable = true)\n",
            "\n",
            "         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatic schema evolution with mergeSchema\n",
        "df2.write \\\n",
        "  .format(\"delta\") \\\n",
        "  .mode(\"append\") \\\n",
        "  .option(\"mergeSchema\", \"true\") \\\n",
        "  .saveAsTable(\"my_delta_table\")\n",
        "\n",
        "query = \"SELECT * FROM my_delta_table ORDER BY col1\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTjGennJ_mvY",
        "outputId": "4f7d1dbb-3d7b-4279-c3fd-218971962e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   1|   A|NULL|\n",
            "|   2|   B|NULL|\n",
            "|   3|   C|NULL|\n",
            "|   4|   D|   X|\n",
            "|   5|   E|   Y|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Audit History\n",
        "\n",
        "Delta Lake log all change details providing a fill audit trail"
      ],
      "metadata": {
        "id": "QpBg1ynfC03S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"DESCRIBE HISTORY my_delta_table\"\n",
        "\n",
        "spark.sql(query).select(\"version\", \"timestamp\", \"operation\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY5HqiLkC5rb",
        "outputId": "1abbe62e-6a69-485a-de6b-1d52081b7688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+----------------------+\n",
            "|version|timestamp              |operation             |\n",
            "+-------+-----------------------+----------------------+\n",
            "|1      |2024-12-19 13:34:14.1  |WRITE                 |\n",
            "|0      |2024-12-19 13:33:49.539|CREATE TABLE AS SELECT|\n",
            "+-------+-----------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. DML Operations\n",
        "\n",
        "Supports merge, update and delete operations"
      ],
      "metadata": {
        "id": "mNJOClc-4wJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPDATE"
      ],
      "metadata": {
        "id": "EkSXZsxU6U8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"UPDATE my_delta_table SET col3 = 'Z' WHERE col3 IS NULL\"\n",
        "\n",
        "spark.sql(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wihcIewJ4uvJ",
        "outputId": "a6b4e8a1-a09e-46b4-db77-8ef2401d6946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[num_affected_rows: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT * FROM my_delta_table ORDER BY col1\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-TiA_GT59Og",
        "outputId": "ced22e49-6553-4021-b13a-5b36c6208189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   1|   A|   Z|\n",
            "|   2|   B|   Z|\n",
            "|   3|   C|   Z|\n",
            "|   4|   D|   X|\n",
            "|   5|   E|   Y|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DELETE"
      ],
      "metadata": {
        "id": "EB1IYlQn-wTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"DELETE FROM my_delta_table WHERE col1 IN (2, 4)\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0xXevQA6XeZ",
        "outputId": "49034dfc-2fbd-47f3-be41-2d7278d904d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|num_affected_rows|\n",
            "+-----------------+\n",
            "|                2|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT * FROM my_delta_table ORDER BY col1\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2HiaKqO-76I",
        "outputId": "0f919838-4ce0-4f5f-9568-a69b0eddda27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   1|   A|   Z|\n",
            "|   3|   C|   Z|\n",
            "|   5|   E|   Y|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DESCRIBE HISTORY"
      ],
      "metadata": {
        "id": "3vuKKe3lCssI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"DESCRIBE HISTORY my_delta_table\"\n",
        "\n",
        "spark.sql(query).select(\"version\", \"timestamp\", \"operation\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy07q38b4SP6",
        "outputId": "a10ab124-ebbd-447e-da67-fddd43e897ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+----------------------+\n",
            "|version|timestamp              |operation             |\n",
            "+-------+-----------------------+----------------------+\n",
            "|3      |2024-12-19 13:34:41.337|DELETE                |\n",
            "|2      |2024-12-19 13:34:29.151|UPDATE                |\n",
            "|1      |2024-12-19 13:34:14.1  |WRITE                 |\n",
            "|0      |2024-12-19 13:33:49.539|CREATE TABLE AS SELECT|\n",
            "+-------+-----------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Time travel\n",
        "\n",
        "Access/revert to earlier versions of data for audits, rollbacks, or reproduce"
      ],
      "metadata": {
        "id": "B71WvLEB_yWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 0 = CREATE TABLE AS SELECT\n",
        "query = \"SELECT * FROM my_delta_table VERSION AS OF 0 ORDER BY col1\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxIx77r9pd2-",
        "outputId": "a66e69fe-3271-422e-9b9e-b44b6108d7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+\n",
            "|col1|col2|\n",
            "+----+----+\n",
            "|   1|   A|\n",
            "|   2|   B|\n",
            "|   3|   C|\n",
            "+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 2 = UPDATE\n",
        "query = \"SELECT * FROM my_delta_table VERSION AS OF 2 ORDER BY col1\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZqmplnuFT3K",
        "outputId": "12e7780a-eb0a-46d9-fcf1-0b1243e98a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   1|   A|   Z|\n",
            "|   2|   B|   Z|\n",
            "|   3|   C|   Z|\n",
            "|   4|   D|   X|\n",
            "|   5|   E|   Y|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Unified Batch/Streaming\n",
        "\n",
        "A table in Delta Lake is a batch table as well as a streaming source and sink"
      ],
      "metadata": {
        "id": "VAZws1uLDR53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch\n",
        "df3 = spark.read.table(\"my_delta_table\")\n",
        "\n",
        "df3.isStreaming"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pOTwpSypKbt",
        "outputId": "38f2a006-714d-4c4c-ee68-9c1beea839b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Streaming\n",
        "df3 = spark.readStream.table(\"my_delta_table\")\n",
        "\n",
        "df3.isStreaming"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsgGoV-YDQrp",
        "outputId": "f0ae18e0-5c43-4f2c-e874-074864231bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}