{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubenCarty/Master-Artificial-Intelligence-UNIR/blob/main/NLP%20/%20mia07_lab_red_transformers_RubenQuispe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "# **Actividad2 :Laboratorio: word embedings y transformers para clasificación de texto**\n",
        "\n",
        "   # **Curso: Natural Language Proccessing**\n",
        "\n",
        "# **Máster Universitario en Inteligencia Artificial**\n",
        "# [Student: RUBEN QUISPE](https://www.linkedin.com/in/ruben-quispe-l/)\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "otTBa1-E3lCR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktFg2jj3jTE6"
      },
      "source": [
        "# ACTIVIDAD DE CLASIFICACIÓN DE TEXTO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ-OuW5DiLJs"
      },
      "source": [
        "En esta actividad vamos a trabajar en clasificar textos. Se recorrerá todo el proceso desde traer el dataset hasta proceder a dicha clasificación. Durante la actividad se llevarán a cabo muchos procesos como la creación de un vocabulario, el uso de embeddings y la creación de modelos.\n",
        "\n",
        "Las cuestiones presentes en esta actividad están basadas en un Notebook creado por François Chollet, uno de los creadores de Keras y autor del libro \"Deep Learning with Python\".\n",
        "\n",
        "En este Notebook se trabaja con el dataset \"Newsgroup20\" que contiene aproximadamente 20000 mensajes que pertenecen a 20 categorías diferentes.\n",
        "\n",
        "El objetivo es entender los conceptos que se trabajan y ser capaz de hacer pequeñas experimentaciones para mejorar el Notebook creado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hytURWLLjZvT"
      },
      "source": [
        "# Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DbxRuvOwkzSs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import pathlib\n",
        "import spacy\n",
        "import en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las bibliotecas necesarias para el manejo de arrays (numpy), para trabajar con TensorFlow y Keras en la construcción de modelos de deep learning (tensorflow y keras), y para manipular archivos y directorios (os, pathlib). También se importa spacy y en_core_web_sm para la manipulación de textos."
      ],
      "metadata": {
        "id": "uFFXeAFMCOvl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXfYbCflkQYy"
      },
      "source": [
        "# Descarga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e-1ZhOf3lB_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d2744f-90c9-4ea6-8011-ee9ecdb38e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "17329808/17329808 [==============================] - 16s 1us/step\n"
          ]
        }
      ],
      "source": [
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se descarga el dataset \"20 Newsgroups\" de una URL específica y se descomprime en la ubicación predeterminada."
      ],
      "metadata": {
        "id": "EgDFpXWFCa9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l3ygvoWhlCYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b80f7f-9e96-4079-8460-e28d69c85f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['rec.sport.hockey', 'talk.politics.mideast', 'talk.politics.misc', 'sci.space', 'rec.motorcycles', 'rec.sport.baseball', 'rec.autos', 'sci.electronics', 'comp.sys.mac.hardware', 'talk.religion.misc', 'sci.med', 'misc.forsale', 'comp.graphics', 'alt.atheism', 'comp.sys.ibm.pc.hardware', 'soc.religion.christian', 'comp.os.ms-windows.misc', 'sci.crypt', 'comp.windows.x', 'talk.politics.guns']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "#Estructura de directorios del dataset\n",
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se obtienen los nombres de los directorios que corresponden a las diferentes categorías del dataset y se imprimen."
      ],
      "metadata": {
        "id": "izwPz4QmCxyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Directorio del Dataset"
      ],
      "metadata": {
        "id": "WB4kRmYADGAm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RdN6J5oT3G7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97585f2b-cac5-4210-cbe9-1cbbbe2a8deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/20_newsgroup\n"
          ]
        }
      ],
      "source": [
        "print(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se imprime el directorio donde se descomprimió el dataset"
      ],
      "metadata": {
        "id": "4Jejf1LhDOQy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OG8rjgOFlcaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee9a73f-c114-4b7d-d59b-bf8b6e916424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38712', '38443', '38572', '39646', '38817']\n"
          ]
        }
      ],
      "source": [
        "#Algunos archivos de la categoria \"com.graphics\"\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se listan los nombres de archivos dentro de la categoría comp.graphics y se imprimen los primeros 5."
      ],
      "metadata": {
        "id": "CiSxo_u2DSnB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8ox6s6z9lgps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dfabdc3-b5f1-478a-f48e-32b77d6cf70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xref: cantaloupe.srv.cs.cmu.edu comp.graphics:37261 alt.graphics:519 comp.graphics.animation:2614\n",
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!zaphod.mps.ohio-state.edu!darwin.sura.net!dtix.dt.navy.mil!oasys!lipman\n",
            "From: lipman@oasys.dt.navy.mil (Robert Lipman)\n",
            "Newsgroups: comp.graphics,alt.graphics,comp.graphics.animation\n",
            "Subject: CALL FOR PRESENTATIONS: Navy SciViz/VR Seminar\n",
            "Message-ID: <32850@oasys.dt.navy.mil>\n",
            "Date: 19 Mar 93 20:10:23 GMT\n",
            "Article-I.D.: oasys.32850\n",
            "Expires: 30 Apr 93 04:00:00 GMT\n",
            "Reply-To: lipman@oasys.dt.navy.mil (Robert Lipman)\n",
            "Followup-To: comp.graphics\n",
            "Distribution: usa\n",
            "Organization: Carderock Division, NSWC, Bethesda, MD\n",
            "Lines: 65\n",
            "\n",
            "\n",
            "\t\t\tCALL FOR PRESENTATIONS\n",
            "\t\n",
            "      NAVY SCIENTIFIC VISUALIZATION AND VIRTUAL REALITY SEMINAR\n",
            "\n",
            "\t\t\tTuesday, June 22, 1993\n",
            "\n",
            "\t    Carderock Division, Naval Surface Warfare Center\n",
            "\t      (formerly the David Taylor Research Center)\n",
            "\t\t\t  Bethesda, Maryland\n",
            "\n",
            "SPONSOR: NESS (Navy Engineering Software System) is sponsoring a \n",
            "one-day Navy Scientific Visualization and Virtual Reality Seminar.  \n",
            "The purpose of the seminar is to present and exchange information for\n",
            "Navy-related scientific visualization and virtual reality programs, \n",
            "research, developments, and applications.\n",
            "\n",
            "PRESENTATIONS: Presentations are solicited on all aspects of \n",
            "Navy-related scientific visualization and virtual reality.  All \n",
            "current work, works-in-progress, and proposed work by Navy \n",
            "organizations will be considered.  Four types of presentations are \n",
            "available.\n",
            "\n",
            "     1. Regular presentation: 20-30 minutes in length\n",
            "     2. Short presentation: 10 minutes in length\n",
            "     3. Video presentation: a stand-alone videotape (author need not \n",
            "\tattend the seminar)\n",
            "     4. Scientific visualization or virtual reality demonstration (BYOH)\n",
            "\n",
            "Accepted presentations will not be published in any proceedings, \n",
            "however, viewgraphs and other materials will be reproduced for \n",
            "seminar attendees.\n",
            "\n",
            "ABSTRACTS: Authors should submit a one page abstract and/or videotape to:\n",
            "\n",
            "     Robert Lipman\n",
            "     Naval Surface Warfare Center, Carderock Division\n",
            "     Code 2042\n",
            "     Bethesda, Maryland  20084-5000\n",
            "\n",
            "     VOICE (301) 227-3618;  FAX (301) 227-5753  \n",
            "     E-MAIL  lipman@oasys.dt.navy.mil\n",
            "\n",
            "Authors should include the type of presentation, their affiliations, \n",
            "addresses, telephone and FAX numbers, and addresses.  Multi-author \n",
            "papers should designate one point of contact.\n",
            "\n",
            "DEADLINES: The abstact submission deadline is April 30, 1993.  \n",
            "Notification of acceptance will be sent by May 14, 1993.  \n",
            "Materials for reproduction must be received by June 1, 1993.\n",
            "\n",
            "For further information, contact Robert Lipman at the above address.\n",
            "\n",
            "\t  PLEASE DISTRIBUTE AS WIDELY AS POSSIBLE, THANKS.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Robert Lipman                     | Internet: lipman@oasys.dt.navy.mil\n",
            "David Taylor Model Basin - CDNSWC |       or: lip@ocean.dt.navy.mil\n",
            "Computational Signatures and      | Voicenet: (301) 227-3618\n",
            "   Structures Group, Code 2042    | Factsnet: (301) 227-5753\n",
            "Bethesda, Maryland  20084-5000    | Phishnet: stockings@long.legs\n",
            "\t\t\t\t   \n",
            "The sixth sick shiek's sixth sheep's sick.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Ejemplo de un texto de la categoría \"com.graphics\"\n",
        "print(open(data_dir / \"comp.graphics\" / \"37261\").read())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se lee y se imprime el contenido de un archivo de ejemplo en la categoría comp.graphics."
      ],
      "metadata": {
        "id": "2uNGlzVRDe1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Archivos de Otra Categoría"
      ],
      "metadata": {
        "id": "_00xOnYnDjqn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vUbbjI8plaG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bde2c72-a522-4bd2-9726-ee2eee841c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in talk.politics.misc: 1000\n",
            "Some example filenames: ['179111', '178944', '178697', '179072', '178742']\n"
          ]
        }
      ],
      "source": [
        "#Algunos archivos de la categoria \"talk.politics.misc\"\n",
        "fnames = os.listdir(data_dir / \"talk.politics.misc\")\n",
        "print(\"Number of files in talk.politics.misc:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se listan los nombres de archivos dentro de la categoría talk.politics.misc y se imprimen los primeros 5."
      ],
      "metadata": {
        "id": "VGSEHN2rDm2M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "izZGWhpklCbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43880b2e-be5f-480e-f2d2-22433e4e6e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xref: cantaloupe.srv.cs.cmu.edu talk.politics.guns:54219 talk.politics.misc:178463\n",
            "Newsgroups: talk.politics.guns,talk.politics.misc\n",
            "Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!darwin.sura.net!martha.utcc.utk.edu!FRANKENSTEIN.CE.UTK.EDU!VEAL\n",
            "From: VEAL@utkvm1.utk.edu (David Veal)\n",
            "Subject: Re: Proof of the Viability of Gun Control\n",
            "Message-ID: <VEAL.749.735192116@utkvm1.utk.edu>\n",
            "Lines: 21\n",
            "Sender: usenet@martha.utcc.utk.edu (USENET News System)\n",
            "Organization: University of Tennessee Division of Continuing Education\n",
            "References: <1qpbqd$ntl@access.digex.net> <C5otvp.ItL@magpie.linknet.com>\n",
            "Date: Mon, 19 Apr 1993 04:01:56 GMT\n",
            "\n",
            "[alt.drugs and alt.conspiracy removed from newsgroups line.]\n",
            "\n",
            "In article <C5otvp.ItL@magpie.linknet.com> neal@magpie.linknet.com (Neal) writes:\n",
            "\n",
            ">   Once the National Guard has been called into federal service,\n",
            ">it is under the command of the present. Tha National Guard, though\n",
            ">defined as the \"Militia\" in the statutes, is actually a reserve component\n",
            ">of the United State Army, and was formed pursuant to the power of Congress\n",
            ">to raise and support Armies.\n",
            "\n",
            "       That's the really cute thing about saying the 2nd amendment\n",
            "only covers the national guard, because that would mean that it\n",
            "essentially prohibits the federal government from disarming a branch\n",
            "of the federal government.\n",
            "\n",
            "       Sounds like a real limit to federal power to me.\n",
            "------------------------------------------------------------------------\n",
            "David Veal Univ. of Tenn. Div. of Cont. Education Info. Services Group\n",
            "PA146008@utkvm1.utk.edu - \"I still remember the way you laughed, the day\n",
            "your pushed me down the elevator shaft;  I'm beginning to think you don't\n",
            "love me anymore.\" - \"Weird Al\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Ejemplo de un texto de la categoría \"talk.politics.misc\"\n",
        "print(open(data_dir / \"talk.politics.misc\" / \"178463\").read())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se lee y se imprime el contenido de un archivo de ejemplo en la categoría talk.politics.misc."
      ],
      "metadata": {
        "id": "nLbcMEarDrEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_all_dir = [\n",
        "    'alt.atheism',\n",
        "    'comp.graphics',\n",
        "    'comp.sys.mac.hardware',\n",
        "    'comp.windows.x',\n",
        "    'misc.forsale',\n",
        "    'rec.autos',\n",
        "    'rec.sport.baseball',\n",
        "    'rec.sport.hockey',\n",
        "    'sci.crypt',\n",
        "    'sci.med',\n",
        "    'sci.space',\n",
        "    'soc.religion.christian',\n",
        "    'talk.politics.guns',\n",
        "    'talk.politics.misc',\n",
        "    'talk.religion.misc'\n",
        "]"
      ],
      "metadata": {
        "id": "21rQuf5B3N3c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define una lista de categorías a utilizar en el análisis."
      ],
      "metadata": {
        "id": "KsLjNco2DxNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesamiento de Archivos"
      ],
      "metadata": {
        "id": "q-A5-jrYD2C7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "33Ay5U6blCd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cc378d-b3b0-4564-ddb5-c848f0c7b984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 14997\n"
          ]
        }
      ],
      "source": [
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "for dirname in list_all_dir:\n",
        "    class_names.append(dirname)\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath)\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding=\"latin-1\")\n",
        "        content = f.read()\n",
        "        lines = content.split(\"\\n\")\n",
        "        lines = lines[10:]\n",
        "        content = \"\\n\".join(lines)\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Se procesan los archivos de cada categoría, leyendo el contenido y almacenándolo en listas de samples y labels. Cada categoría recibe un índice único."
      ],
      "metadata": {
        "id": "kgQXLB7rD7LU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pmvE6gMcxT"
      },
      "source": [
        "# Mezclando los datos para separarlos en Traning y Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DYX7x-k_lCgZ"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data\n",
        "seed = 1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "keras.utils.set_random_seed(seed)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "* Semilla (seed): Establece una semilla para asegurar que los resultados sean reproducibles.\n",
        "* Mezcla (shuffle): Mezcla los samples (muestras) y labels (etiquetas) para asegurar que los datos de entrenamiento y prueba sean representativos de la variedad de datos disponibles.\n",
        "* División en Entrenamiento y Validación: Se divide el conjunto de datos en entrenamiento (80%) y validación (20%).\n",
        "- Reflexión: La mezcla de los datos antes de dividirlos garantiza que ambas particiones (entrenamiento y validación) sean representativas, evitando sesgos que puedan afectar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "XqrPu6oFJLd3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IktOtKfpNx8E"
      },
      "source": [
        "# Tokenización de las palabras con TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QjHgQPX8lCjO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TextVectorization: Crea un vectorizador de texto que limita el vocabulario a 20,000 palabras y establece una longitud máxima de secuencia de 200.\n",
        "* Adaptación del Vectorizador: Se adapta el vectorizador al conjunto de datos de entrenamiento, permitiéndole aprender el vocabulario.\n",
        "- Reflexión: La tokenización es crucial para convertir el texto en una representación numérica que el modelo pueda procesar. El ajuste del vectorizador al dataset de entrenamiento asegura que el vocabulario relevante sea capturado."
      ],
      "metadata": {
        "id": "liCf8ZlnLMx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualización y Verificación de la Tokenización"
      ],
      "metadata": {
        "id": "X_h8m9CILsBf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vIWC37s5smZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591af04d-edb9-412a-8ecb-d89fcf42f761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "vectorizer.get_vocabulary()[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeros 5 tokens del vocabulario, donde [UNK] representa palabras desconocidas."
      ],
      "metadata": {
        "id": "E2Oc8FXXMV3B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vit8TPqTvmwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1a73d0-4c50-4997-8b7c-69bdb454c3c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(vectorizer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20000: Longitud del vocabulario."
      ],
      "metadata": {
        "id": "412r1UtqMcM7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O-FXA9wPVkg"
      },
      "source": [
        "# Viendo la salida de Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rseIF0fLmyJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae9644e-69e6-4e87-d323-c5ec617c53bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 4079, 1984,   17,    2, 5135])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "output = vectorizer([[\"the cat sat on the mat\"]])\n",
        "output.numpy()[0, :6]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([ 2, 4079, 1984, 17, 2, 5135]): Tokens correspondientes a la frase \"the cat sat on the mat\"."
      ],
      "metadata": {
        "id": "DnSQJ3KIMgG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Wsr4AQtBFArV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e4b38c-9083-4972-d15b-f42284a85372"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 200), dtype=int64, numpy=\n",
              "array([[   2, 4079, 1984,   17,    2, 5135,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reflexión: Verificar el vocabulario y las secuencias tokenizadas asegura que el proceso de tokenización está funcionando correctamente, proporcionando una buena base para el entrenamiento del modelo."
      ],
      "metadata": {
        "id": "p4lgpfs-MjXq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SL5ag8UamzwL"
      },
      "outputs": [],
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "08v8SKcsn3lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23959686-bb85-4ca6-af98-b1581f9c949a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4079, 1984, 17, 2, 5135]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[w] for w in test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eBhadrvOTNZ"
      },
      "source": [
        "# Tokenización de los datos de entrenamiento y validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "W26LUr2dKTOj"
      },
      "outputs": [],
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "- Tokenización: Aplica el vectorizador a las muestras de entrenamiento y validación, convirtiéndolas en secuencias numéricas.\n",
        "- Conversión a NumPy: Convierte las secuencias y etiquetas a arrays de NumPy.\n",
        "- Reflexión: Este paso transforma el texto en un formato adecuado para ser procesado por redes neuronales, asegurando una correcta entrada de datos al modelo."
      ],
      "metadata": {
        "id": "fEbNTCu8M043"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3QVIb84Olda"
      },
      "source": [
        "# Creación y entrenamiento del modelo. Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B9VxI-i69cdB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U4d3EqEp3G7b"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "- TransformerBlock: Implementa un bloque de transformador con atención multi-cabeza y una red neuronal feed-forward.\n",
        "- TokenAndPositionEmbedding: Combina embeddings de tokens y posiciones, cruciales para que el transformador entienda la posición de las palabras en la secuencia."
      ],
      "metadata": {
        "id": "wgdXuMZ1Nkdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcción del Modelo:"
      ],
      "metadata": {
        "id": "3pK9PW1YN3-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xae1oDI_3G7b"
      },
      "outputs": [],
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "num_tokens = len(voc) + 2\n",
        "\n",
        "maxlen = 200\n",
        "vocab_size = num_tokens\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "\n",
        "modeloTransformers = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "- Estructura del Modelo: Construye el modelo de transformador, agregando capas de embedding, bloques de transformador, pooling, y capas densas para la clasificación final."
      ],
      "metadata": {
        "id": "ydwB4-H1N9tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del Modelo:"
      ],
      "metadata": {
        "id": "1TslKjTXOBw-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_NtYhJum3G7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed10949-3cd4-4fd9-d98a-6829a8ad9b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "94/94 [==============================] - 77s 776ms/step - loss: 2.6455 - acc: 0.1109 - val_loss: 2.5149 - val_acc: 0.1777\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - 72s 770ms/step - loss: 2.3198 - acc: 0.2316 - val_loss: 1.9955 - val_acc: 0.3968\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - 77s 820ms/step - loss: 1.8106 - acc: 0.4104 - val_loss: 1.4374 - val_acc: 0.5505\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - 64s 686ms/step - loss: 1.3341 - acc: 0.5578 - val_loss: 1.0937 - val_acc: 0.6442\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - 64s 685ms/step - loss: 1.0036 - acc: 0.6679 - val_loss: 1.1865 - val_acc: 0.6119\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - 69s 740ms/step - loss: 0.8298 - acc: 0.7294 - val_loss: 1.0961 - val_acc: 0.6445\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - 68s 725ms/step - loss: 0.6774 - acc: 0.7805 - val_loss: 1.0161 - val_acc: 0.6786\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - 68s 726ms/step - loss: 0.5939 - acc: 0.8055 - val_loss: 0.8738 - val_acc: 0.7406\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - 63s 678ms/step - loss: 0.5295 - acc: 0.8255 - val_loss: 0.6673 - val_acc: 0.7879\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - 69s 741ms/step - loss: 0.4518 - acc: 0.8516 - val_loss: 0.7437 - val_acc: 0.7759\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - 68s 726ms/step - loss: 0.4186 - acc: 0.8581 - val_loss: 0.7861 - val_acc: 0.7669\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - 66s 704ms/step - loss: 0.3828 - acc: 0.8739 - val_loss: 0.6244 - val_acc: 0.8053\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - 67s 710ms/step - loss: 0.3347 - acc: 0.8935 - val_loss: 0.7089 - val_acc: 0.7913\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - 66s 704ms/step - loss: 0.2939 - acc: 0.9024 - val_loss: 0.6969 - val_acc: 0.7999\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - 62s 662ms/step - loss: 0.2560 - acc: 0.9130 - val_loss: 1.1530 - val_acc: 0.7546\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - 76s 813ms/step - loss: 0.2364 - acc: 0.9211 - val_loss: 0.8177 - val_acc: 0.7783\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - 72s 767ms/step - loss: 0.2070 - acc: 0.9269 - val_loss: 0.7629 - val_acc: 0.8106\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - 68s 725ms/step - loss: 0.1900 - acc: 0.9351 - val_loss: 0.7800 - val_acc: 0.8059\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - 73s 779ms/step - loss: 0.1641 - acc: 0.9423 - val_loss: 0.7268 - val_acc: 0.8256\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - 67s 710ms/step - loss: 0.1510 - acc: 0.9455 - val_loss: 0.7577 - val_acc: 0.8226\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, 200, 32)           646464    \n",
            " ng (TokenAndPositionEmbedd                                      \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_block (Transfo  (None, 200, 32)           10656     \n",
            " rmerBlock)                                                      \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 32)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 15)                315       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 658095 (2.51 MB)\n",
            "Trainable params: 658095 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "modeloTransformers.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
        "modeloTransformers.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n",
        "print(modeloTransformers.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados de Entrenamiento:\n",
        "\n",
        "- El modelo muestra un aumento en la precisión de entrenamiento y validación a lo largo de las épocas, alcanzando una precisión de validación de alrededor del 82.6%.\n",
        "- Reflexión: Utilizar un modelo de transformador permite capturar relaciones complejas en el texto, mejorando la capacidad del modelo para clasificar textos en diferentes categorías."
      ],
      "metadata": {
        "id": "VJzxTpsLORxi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4x_4eXJVrnX"
      },
      "source": [
        "# Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fgg7KnoioNYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "bbe80276-13fb-4c99-ae3b-3fcf881419b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'comp.graphics'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = modeloTransformers(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end_to_end_model.predict(\n",
        "    [[\"this message is about computer graphics and 3D modeling\"]]\n",
        ")\n",
        "\n",
        "class_names[np.argmax(probabilities[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R-EXfK6qoSAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c16e1346-254a-4329-a64b-4ab457d9fe16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.guns'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "probabilities = end_to_end_model.predict(\n",
        "    [[\"politics and federal courts law that people understand with politician and elects congressman\"]]\n",
        ")\n",
        "\n",
        "class_names[np.argmax(probabilities[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QByfYDv4rGqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c3d06a9c-d705-437d-cda3-4bdb569fa6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alt.atheism'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "probabilities = end_to_end_model.predict(\n",
        "    [[\"we are talking about religion\"]]\n",
        ")\n",
        "\n",
        "class_names[np.argmax(probabilities[0])]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados:\n",
        "\n",
        "- \"comp.graphics\": Correctamente clasifica un mensaje sobre gráficos computacionales.\n",
        "- \"talk.politics.guns\": Correctamente clasifica un mensaje sobre política y leyes federales.\n",
        "- \"alt.atheism\": Correctamente clasifica un mensaje sobre religión.\n",
        "- Reflexión: Evaluar el modelo con ejemplos reales asegura que el modelo no solo funciona bien en los datos de entrenamiento y validación, sino que también generaliza bien a nuevos datos."
      ],
      "metadata": {
        "id": "UhSlOCZ9OeRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para mejorar la precisión del modelo en la clasificación de texto usando embeddings y transformadores, podemos considerar varias técnicas. Aquí hay algunas estrategias comunes para optimizar un modelo de NLP:\n",
        "\n",
        "1. Aumento del tamaño del modelo: Incrementar el número de capas o neuronas en cada capa puede permitir al modelo capturar relaciones más complejas.\n",
        "2. Aumento del tamaño de los embeddings: Aumentar la dimensión de los embeddings puede mejorar la capacidad del modelo para representar las características semánticas de las palabras.\n",
        "3. Ajuste de hiperparámetros: Experimentar con diferentes tasas de aprendizaje, optimizadores y tamaños de batch.\n",
        "4. Uso de pre-entrenamientos: Utilizar embeddings pre-entrenados como GloVe o Word2Vec.\n",
        "5. Regularización: Agregar técnicas como Dropout o L2 regularización para evitar el sobreajuste."
      ],
      "metadata": {
        "id": "Oz70RP6FPRNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codigo que trate de optimizar"
      ],
      "metadata": {
        "id": "YKK_QI4LPqZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import numpy as np\n",
        "\n",
        "# Semilla para reproducibilidad\n",
        "seed = 1337\n",
        "keras.utils.set_random_seed(seed)\n",
        "\n",
        "# Ejemplo de datos (reemplaza esto con tus datos reales)\n",
        "samples = [\n",
        "    \"this is a sample text\",\n",
        "    \"another sample text for classification\",\n",
        "    \"machine learning is fascinating\",\n",
        "    \"deep learning models are powerful\",\n",
        "    \"natural language processing is a complex field\"\n",
        "]\n",
        "labels = [0, 1, 0, 1, 0]  # Ejemplo de etiquetas (reemplaza esto con tus etiquetas reales)\n",
        "\n",
        "# Mezclar los datos\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Dividir en entrenamiento y validación\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]\n",
        "\n",
        "# Tokenización\n",
        "max_tokens = 30000\n",
        "max_len = 250\n",
        "vectorizer = TextVectorization(max_tokens=max_tokens, output_sequence_length=max_len)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)\n",
        "\n",
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "\n",
        "# Modelo de Transformer\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "# Hiperparámetros optimizados\n",
        "embed_dim = 64  # Tamaño de la incrustación\n",
        "num_heads = 4  # Número de cabezas de atención\n",
        "ff_dim = 128  # Tamaño de la red de alimentación\n",
        "num_tokens = len(vectorizer.get_vocabulary()) + 2\n",
        "maxlen = 250\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, num_tokens, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(15, activation=\"softmax\")(x)  # Ajusta el número de clases según tu problema\n",
        "\n",
        "modeloTransformers = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compilación del modelo\n",
        "modeloTransformers.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = modeloTransformers.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=30,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Evaluación del modelo\n",
        "print(modeloTransformers.summary())\n",
        "\n",
        "# Pruebas con el modelo entrenado\n",
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = modeloTransformers(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "# Ejemplo de predicción\n",
        "test_samples = [\n",
        "    \"this message is about computer graphics and 3D modeling\",\n",
        "    \"politics and federal courts law that people understand with politician and elects congressman\",\n",
        "    \"we are talking about religion\"\n",
        "]\n",
        "\n",
        "for sample in test_samples:\n",
        "    probabilities = end_to_end_model.predict([[sample]])\n",
        "    print(f\"Text: {sample}\")\n",
        "    print(f\"Predicted Class: {np.argmax(probabilities[0])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ1oxoVPUYc4",
        "outputId": "41f9d404-d812-4027-c7a5-43d14ae4c5d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.0730 - accuracy: 0.5000 - val_loss: 1.3467 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.0250 - accuracy: 0.5000 - val_loss: 1.2569 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 1.8410 - accuracy: 0.2500 - val_loss: 1.1775 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.4322 - accuracy: 0.7500 - val_loss: 1.1076 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.4959 - accuracy: 0.5000 - val_loss: 1.0419 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.4762 - accuracy: 0.2500 - val_loss: 0.9894 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.4383 - accuracy: 0.5000 - val_loss: 0.9459 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.3563 - accuracy: 0.2500 - val_loss: 0.9057 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.3109 - accuracy: 0.2500 - val_loss: 0.8719 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 1.1996 - accuracy: 0.5000 - val_loss: 0.8466 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.1186 - accuracy: 0.5000 - val_loss: 0.8306 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.2285 - accuracy: 0.2500 - val_loss: 0.8256 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.1694 - accuracy: 0.5000 - val_loss: 0.8278 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 1.2894 - accuracy: 0.0000e+00 - val_loss: 0.8314 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.0323 - accuracy: 0.2500 - val_loss: 0.8386 - val_accuracy: 1.0000\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 250)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, 250, 64)           17216     \n",
            " ng_2 (TokenAndPositionEmbe                                      \n",
            " dding)                                                          \n",
            "                                                                 \n",
            " transformer_block_2 (Trans  (None, 250, 64)           83200     \n",
            " formerBlock)                                                    \n",
            "                                                                 \n",
            " global_average_pooling1d_2  (None, 64)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 15)                975       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 105551 (412.31 KB)\n",
            "Trainable params: 105551 (412.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "1/1 [==============================] - 1s 898ms/step\n",
            "Text: this message is about computer graphics and 3D modeling\n",
            "Predicted Class: 0\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "Text: politics and federal courts law that people understand with politician and elects congressman\n",
            "Predicted Class: 0\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Text: we are talking about religion\n",
            "Predicted Class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de Resultados y Reflexiones\n",
        "Vamos a desglosar y analizar los resultados obtenidos tras entrenar y evaluar el modelo Transformer para clasificación de texto.\n",
        "\n",
        "- Resultados del Entrenamiento\n",
        "- Epoch 1/30\n",
        "\n",
        "- loss: 2.0730 - accuracy: 0.5000 - val_loss: 1.3467 - val_accuracy: 1.0000\n",
        "- Epoch 2/30\n",
        "\n",
        "- loss: 2.0250 - accuracy: 0.5000 - val_loss: 1.2569 - val_accuracy: 1.0000\n",
        "- Epoch 3/30\n",
        "\n",
        "- loss: 1.8410 - accuracy: 0.2500 - val_loss: 1.1775 - val_accuracy: 1.0000\n",
        "... y así sucesivamente hasta:\n",
        "\n",
        "- Epoch 15/30\n",
        "\n",
        "- loss: 1.0323 - accuracy: 0.2500 - val_loss: 0.8386 - val_accuracy: 1.0000\n",
        "## Observaciones y Reflexiones\n",
        "1. Desempeño en Entrenamiento vs Validación:\n",
        "\n",
        "- Exactitud de Entrenamiento: La exactitud de entrenamiento fluctúa notablemente, comenzando en 50% y disminuyendo a valores tan bajos como 0% en algunas épocas. Esto sugiere que el modelo no está aprendiendo de manera consistente de los datos de entrenamiento.\n",
        "- Exactitud de Validación: La exactitud de validación es consistentemente del 100% desde la primera época. Esto es un indicador claro de sobreajuste, donde el modelo ha memorizado el conjunto de validación (probablemente debido a su pequeño tamaño) y no está generalizando correctamente.\n",
        "2. Pérdida de Entrenamiento y Validación:\n",
        "\n",
        "- La pérdida de entrenamiento disminuye gradualmente, lo cual es esperado, pero la exactitud no sigue una tendencia consistente.\n",
        "- La pérdida de validación también disminuye, pero dado el contexto de la exactitud de validación, esto refuerza la sospecha de sobreajuste.\n",
        "Predicciones del Modelo:\n",
        "\n",
        "3. Para los ejemplos de texto proporcionados, el modelo predice consistentemente la clase 0, lo cual indica que el modelo no está bien ajustado y probablemente está sesgado hacia una única clase, nuevamente debido al sobreajuste.\n"
      ],
      "metadata": {
        "id": "QTt-LeHWWBps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflexiones\n",
        "1. Tamaño del Conjunto de Datos:\n",
        "\n",
        "- Los datos de entrenamiento y validación son extremadamente limitados. Con sólo 5 ejemplos, el modelo no tiene suficiente información para aprender adecuadamente los patrones subyacentes. En aplicaciones de NLP, se recomienda tener un conjunto de datos mucho más grande.\n",
        "2. Ajuste de Hiperparámetros:\n",
        "\n",
        "- Aunque los hiperparámetros del modelo están optimizados, con una mayor capacidad de representación, no pueden compensar la falta de datos. Debería considerarse reducir la complejidad del modelo o, idealmente, aumentar significativamente el tamaño del conjunto de datos.\n",
        "3. Validación Cruzada:\n",
        "\n",
        "- En lugar de dividir los datos en entrenamiento y validación de manera estática, usar validación cruzada puede proporcionar una mejor estimación del rendimiento del modelo, especialmente con un conjunto de datos pequeño.\n",
        "4. Regularización:\n",
        "\n",
        "- Aunque se utilizó Dropout, la regularización adicional, como el uso de una tasa de Dropout más alta, o la adición de regularización L2, puede ayudar a mitigar el sobreajuste.\n",
        "5. Preprocesamiento de Datos:\n",
        "\n",
        "- Asegurarse de que el preprocesamiento de datos sea robusto y que todas las clases estén representadas equitativamente en los datos de entrenamiento y validación.\n",
        "\n"
      ],
      "metadata": {
        "id": "3CXHXTZxWziN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8wM4_8R73i7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Propuestas para Mejorar el Modelo\n",
        "1. Aumentar el Conjunto de Datos:\n",
        "\n",
        "- Obtener más datos de entrenamiento es la prioridad número uno. Un modelo Transformer necesita una cantidad considerable de datos para entrenar efectivamente.\n",
        "2. Simplificar el Modelo:\n",
        "\n",
        "- Considerar usar un modelo menos complejo si no se pueden obtener más datos. Modelos más simples tienen menos riesgo de sobreajuste en conjuntos de datos pequeños.\n",
        "3. Validación Cruzada:\n",
        "\n",
        "- Implementar validación cruzada para obtener una mejor comprensión de la capacidad de generalización del modelo.\n",
        "4. Regularización Adicional:\n",
        "\n",
        "- Incrementar la regularización, ya sea aumentando la tasa de Dropout o añadiendo regularización L2.\n",
        "5. Mejor Manejo del Preprocesamiento:\n",
        "\n",
        "- Asegurar que el preprocesamiento de datos no introduce sesgos y que todas las clases estén equilibradas.\n",
        "- En conclusión, aunque los Transformers son poderosos y versátiles, su efectividad depende en gran medida de la cantidad y calidad de los datos de entrenamiento. La clave para mejorar la precisión en este contexto es primero aumentar y mejorar el conjunto de datos, y luego ajustar el modelo en consecuencia.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VSR_zNXGYP_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SOLUCION DE LAS 9 PREGUNTAS CON CODIGO"
      ],
      "metadata": {
        "id": "sMeKI_habV5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 1: Cálculo del número promedio de tokens con Spacy"
      ],
      "metadata": {
        "id": "R5H7KrzIbu02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Cargar modelo de Spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Descargar datos\n",
        "categories = ['comp.graphics']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "\n",
        "# Obtener 15 documentos\n",
        "sample_texts = newsgroups_train.data[:15]\n",
        "\n",
        "# Tokenizar y calcular promedio de tokens\n",
        "num_tokens = [len(nlp(text)) for text in sample_texts]\n",
        "avg_tokens = sum(num_tokens) / len(num_tokens)\n",
        "\n",
        "print(f\"Número promedio de tokens: {avg_tokens}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZVw0eBxWyg9",
        "outputId": "1e0059f9-d475-4b18-ffe0-00d7dd663075"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número promedio de tokens: 376.93333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación del Resultado de la Pregunta 1\n",
        "- El resultado obtenido, Número promedio de tokens: 376.93333333333334, indica que, en promedio, los documentos de la categoría \"comp.graphics\" tienen aproximadamente 377 tokens. A continuación, se ofrece una explicación más detallada sobre este resultado y su relevancia en el contexto del procesamiento del lenguaje natural (NLP)."
      ],
      "metadata": {
        "id": "mCcRwcpIcqQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 2: Descarte de las primeras diez líneas"
      ],
      "metadata": {
        "id": "9otQGbEqdOYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_clean(file_path):\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        lines = file.readlines()\n",
        "    cleaned_lines = lines[10:]\n",
        "    return \" \".join(cleaned_lines)\n"
      ],
      "metadata": {
        "id": "TW60PqldcvXo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las primeras diez líneas de cada fichero pueden contener metadatos, encabezados o información que no es relevante para el análisis del contenido principal del texto. Se eligen diez líneas como un número arbitrario pero razonable para asegurarse de que se excluye esta información."
      ],
      "metadata": {
        "id": "-rBTaLqgeFmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para leer y preprocesar documentos\n",
        "def preprocess_text(text):\n",
        "    # Dividir el texto en líneas\n",
        "    lines = text.split('\\n')\n",
        "    # Descartar las primeras diez líneas\n",
        "    lines = lines[10:]\n",
        "    # Unir las líneas restantes en un solo texto\n",
        "    text = '\\n'.join(lines)\n",
        "    return text\n",
        "\n",
        "# Aplicar la función a todos los documentos\n",
        "processed_texts = [preprocess_text(text) for text in newsgroups_train.data]\n"
      ],
      "metadata": {
        "id": "nRkjcFtVeIn4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 3: Control del parámetro validation_split"
      ],
      "metadata": {
        "id": "GYK_C14HiyM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_split = 0.2\n"
      ],
      "metadata": {
        "id": "0ctFYZp0i0sV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregunta 4: Ejemplo de train_samples, val_samples, train_labels, y val_labels"
      ],
      "metadata": {
        "id": "dgFD-SdgjbWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ejemplo de train_samples: {train_samples[0]}\")\n",
        "print(f\"Ejemplo de val_samples: {val_samples[0]}\")\n",
        "print(f\"Ejemplo de train_labels: {train_labels[0]}\")\n",
        "print(f\"Ejemplo de val_labels: {val_labels[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVgrhK8Ijcq1",
        "outputId": "7d131429-e442-41f9-c297-0d4a29493c15"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de train_samples: deep learning models are powerful\n",
            "Ejemplo de val_samples: natural language processing is a complex field\n",
            "Ejemplo de train_labels: 1\n",
            "Ejemplo de val_labels: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 5: output_sequence_length"
      ],
      "metadata": {
        "id": "mAk1j2MAqcXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=30000, output_sequence_length=200)"
      ],
      "metadata": {
        "id": "4ALmbrLOqdIj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaZlCuCoqzwy",
        "outputId": "fab16696-8ce1-48f6-b38b-cd401041d52a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.preprocessing.text_vectorization.TextVectorization at 0x794ad7060280>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 6: Precisión del modelo"
      ],
      "metadata": {
        "id": "lhOqTdWEsEAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumiendo que el modelo ha sido entrenado como se mostró anteriormente:\n",
        "train_accuracy = model.evaluate(x_train, y_train, verbose=0)[1]\n",
        "val_accuracy = model.evaluate(x_val, y_val, verbose=0)[1]\n",
        "\n",
        "print(f\"Precisión en el conjunto de entrenamiento: {train_accuracy}\")\n",
        "print(f\"Precisión en el conjunto de validación: {val_accuracy}\")\n"
      ],
      "metadata": {
        "id": "xsQeGVdXuEGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 7: Análisis cualitativo de la salida"
      ],
      "metadata": {
        "id": "Db3ZJmEtuqpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos de prueba\n",
        "test_samples = [\n",
        "    \"this message is about computer graphics and 3D modeling\",\n",
        "    \"politics and federal courts law that people understand with politician and elects congressman\",\n",
        "    \"we are talking about religion\"\n",
        "]\n",
        "\n",
        "# Realizar predicciones y mostrar resultados\n",
        "for sample in test_samples:\n",
        "    probabilities = end_to_end_model.predict([[sample]])\n",
        "    predicted_class = np.argmax(probabilities[0])\n",
        "    print(f\"Texto: {sample}\")\n",
        "    print(f\"Clase Predicha: {predicted_class}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY2J6Sozuzu8",
        "outputId": "f14f3239-f070-4ed8-b9f4-a6424a7a9025"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n",
            "Texto: this message is about computer graphics and 3D modeling\n",
            "Clase Predicha: 0\n",
            "\n",
            "1/1 [==============================] - 1s 816ms/step\n",
            "Texto: politics and federal courts law that people understand with politician and elects congressman\n",
            "Clase Predicha: 0\n",
            "\n",
            "1/1 [==============================] - 0s 299ms/step\n",
            "Texto: we are talking about religion\n",
            "Clase Predicha: 0\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}